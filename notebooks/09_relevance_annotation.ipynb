{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08bae01-173d-4ff6-8aa8-415f6665da25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "data_path = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eedcaa-95ad-4626-a7f1-dac16c05e336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(ranked, img_path, relevances=None):\n",
    "    fig = plt.figure(figsize=(20,20)) # specifying the overall grid size\n",
    "    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(int(math.ceil(len(ranked)/4)),4),\n",
    "                 axes_pad=0.3,  share_all=True\n",
    "                 )\n",
    "    if relevances is None:\n",
    "        relevances = np.zeros(len(ranked))\n",
    "    for ax, rank, relevance in zip(grid, ranked, relevances):\n",
    "        rico_id = rank\n",
    "        img = Image.open(img_path + str(rico_id) + \".jpg\")\n",
    "        img = img.resize((1080, 1920))\n",
    "        ax.imshow(np.array(img))\n",
    "        ax.grid(False)\n",
    "        title = str(rico_id)\n",
    "        if relevance != 0:\n",
    "            title += \", \" + relevance\n",
    "        ax.title.set_text(title)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a3eb3-87e9-4736-840d-d63846764497",
   "metadata": {},
   "source": [
    "# 1. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077e33c-8089-4544-aff9-0de78050e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(data_path + \"dataset_test_k_top_20.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db91b1ac-99db-4e57-8aa4-c62b50ec4b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_0 = pd.read_excel(data_path + \"annotation_0.xlsx\")\n",
    "anno_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fbb1c6-eb43-479b-bc9b-d93e844933f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_1 = pd.read_excel(data_path + \"annotation_1.xlsx\")\n",
    "anno_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9044d2-8ad4-440a-95de-1386e6b4542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_2 = pd.read_excel(data_path + \"annotation_2.xlsx\")\n",
    "anno_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3b1dad-f8be-4100-9762-652d6f4e744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"anno_0\"] = \"\"\n",
    "dataset[\"anno_1\"] = \"\"\n",
    "dataset[\"anno_2\"] = \"\"\n",
    "concat_0 = []\n",
    "concat_1 = []\n",
    "concat_2 = []\n",
    "for index, row in anno_0.iterrows():\n",
    "    annos = []\n",
    "    for i in range(20):\n",
    "        annos.append(row[\"annotation_\" + str(i)])\n",
    "    dataset.at[index, \"anno_0\"] = annos\n",
    "    concat_0.extend(annos)\n",
    "\n",
    "for index, row in anno_1.iterrows():\n",
    "    annos = []\n",
    "    for i in range(20):\n",
    "        annos.append(row[\"annotation_\" + str(i)])\n",
    "    dataset.at[index, \"anno_1\"] = annos\n",
    "    concat_1.extend(annos)\n",
    "\n",
    "for index, row in anno_2.iterrows():\n",
    "    annos = []\n",
    "    for i in range(20):\n",
    "        annos.append(row[\"annotation_\" + str(i)])\n",
    "    dataset.at[index, \"anno_2\"] = annos\n",
    "    concat_2.extend(annos)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1bb4ac-c544-40d3-885e-f8317f0c9896",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "not_unanimous = 0\n",
    "dataset[\"anno_majority\"] = \"\"\n",
    "for index, row in dataset.iterrows():\n",
    "    anno = []\n",
    "    for i in range(20):\n",
    "        annos = []\n",
    "        for j in range(3):\n",
    "            annos.append(row[\"anno_\"+str(j)][i])\n",
    "        values, counts = np.unique(np.array(annos), return_counts=True)\n",
    "        if np.max(counts) != 3:\n",
    "            not_unanimous += 1\n",
    "            print(counts)\n",
    "            print(annos)\n",
    "            print()\n",
    "        anno.append(values[np.argmax(counts)])\n",
    "    dataset.at[index, \"anno_majority\"] = anno\n",
    "not_un_rate = not_unanimous/1000\n",
    "print(not_un_rate)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3ae16-4d2e-4fce-a6dc-5221f3af24d4",
   "metadata": {},
   "source": [
    "# 2. Fleiss Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae303dab-9f1b-4a15-b2a3-1fcdaa55023b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "k = 2\n",
    "\n",
    "fleiss_matrix = np.zeros((N, k))\n",
    "for i in range(N):\n",
    "    fleiss_matrix[i][concat_0[i]] += 1\n",
    "    fleiss_matrix[i][concat_1[i]] += 1\n",
    "    fleiss_matrix[i][concat_2[i]] += 1\n",
    "fleiss_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80157322-8f1f-4eab-893f-25362dac8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fleiss_kappa(fleiss_matrix):\n",
    "    N = fleiss_matrix.shape[0]\n",
    "    k = fleiss_matrix.shape[1]\n",
    "    n = np.sum(fleiss_matrix[0])\n",
    "\n",
    "    print(\"N\", N, \"k\", k, \"n\", n)\n",
    "    \n",
    "    p_is = np.empty((k))\n",
    "    for i in range(k):\n",
    "        p_is[i] = 1/(N*n)*np.sum(fleiss_matrix, axis = 0)[i]\n",
    "        \n",
    "    P_is = np.empty((N))\n",
    "    first_part = 1/(n*(n-1))\n",
    "    for i in range(N):\n",
    "        second_part = 0\n",
    "        for j in range(k):\n",
    "            second_part += fleiss_matrix[i][j]*fleiss_matrix[i][j]\n",
    "        second_part -= n\n",
    "        P_is[i] = first_part * second_part\n",
    "        \n",
    "    P_dash = np.mean(P_is)\n",
    "    \n",
    "    P_dash_e = 0\n",
    "    for i in range(k):\n",
    "        P_dash_e += p_is[i]*p_is[i]\n",
    "\n",
    "    kappa = (P_dash - P_dash_e)/(1 - P_dash_e)\n",
    "    return kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be27ba8-df50-48a4-9a81-30914171c5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fleiss_kappa(fleiss_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e148eebe-9ba8-468b-8c8c-69ecfa0c66e8",
   "metadata": {},
   "source": [
    "# 3. Comparison with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3394fd43-59d7-44b6-9f3e-0cc44e383d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_annotations = pd.read_csv(data_path + \"dataset_test_k_top_20_binary_one_to_ten_annotated.csv\")\n",
    "gpt_annotations = gpt_annotations[[\"RICO GUI\", \"Descriptions\", \"Length\", \"rico_ranking\", \"binary_annotation\", \"binary_reasonings\"]]\n",
    "gpt_annotations[\"binary_annotation\"] = gpt_annotations[\"binary_annotation\"].apply(ast.literal_eval)\n",
    "gpt_annotations[\"binary_reasonings\"] = gpt_annotations[\"binary_reasonings\"].apply(ast.literal_eval)\n",
    "gpt_annotations[\"rico_ranking\"] = gpt_annotations[\"rico_ranking\"].apply(ast.literal_eval)\n",
    "gpt_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065d53d-8b42-44e6-978c-009d755cf783",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in gpt_annotations.iterrows():\n",
    "    ranking = row[\"rico_ranking\"]\n",
    "    binary = row[\"binary_annotation\"]\n",
    "    reasonings = row[\"binary_reasonings\"]\n",
    "    new_ranking = [x for x,_ in sorted(zip(ranking, binary))]#, key=lambda x: x[0])]\n",
    "    new_binary = [x for _,x in sorted(zip(ranking, binary))]#, key=lambda x: x[0])]\n",
    "    new_reasonings = [x for _,x in sorted(zip(ranking, reasonings))]\n",
    "    gpt_annotations.at[index, \"rico_ranking\"] = new_ranking\n",
    "    gpt_annotations.at[index, \"binary_annotation\"] = new_binary\n",
    "    gpt_annotations.at[index, \"binary_reasonings\"] = new_reasonings\n",
    "gpt_annotations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828b4732-8b87-448a-a49d-06b3f165129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = gpt_annotations.join(dataset[[\"RICO GUI\", \"anno_majority\"]].set_index(\"RICO GUI\"), on = \"RICO GUI\")\n",
    "joined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e09604e-b994-40c7-bfd1-4894ecf4bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.to_csv(data_path + \"dataset_test_k_top_20_binary_majority_annotation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e1591-ca77-4c48-90e0-dfae5d9c70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positives = 0\n",
    "pred_positives = 0\n",
    "pred_true_positives = 0\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for index, row in joined.iterrows():\n",
    "    binary = row[\"binary_annotation\"]\n",
    "    truth = row[\"anno_majority\"]\n",
    "    for i in range(len(binary)):\n",
    "        y_true.append(truth[i])\n",
    "        y_pred.append(binary[i])\n",
    "        if truth[i] == 1:\n",
    "            true_positives += 1\n",
    "        if binary[i] == 1:\n",
    "            pred_positives += 1\n",
    "            if truth[i] == 1:\n",
    "                pred_true_positives += 1\n",
    "\n",
    "print(true_positives, pred_positives, pred_true_positives)\n",
    "precision = float(pred_true_positives)/float(pred_positives)\n",
    "recall = float(pred_true_positives)/float(true_positives)\n",
    "f1 = 2*(precision*recall)/(precision + recall)\n",
    "print(\"PRECISION\", precision)\n",
    "print(\"RECALL\", recall)\n",
    "print(\"F1\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87abe208-f0a0-4be9-90db-3ad743a0d3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad576b40-5595-4ec5-bd8c-8dab97be4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_relevants = 0\n",
    "for index, row in joined.iterrows():\n",
    "    if np.sum(np.array(row[\"anno_majority\"])) == 0:\n",
    "        no_relevants += 1\n",
    "        print(index, row[\"Descriptions\"])\n",
    "print(no_relevants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c9ff44-d034-4bd2-9520-c5049d3f0cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_positives = []\n",
    "for index, row in joined.iterrows():\n",
    "    for i in range(20):\n",
    "        if row[\"anno_majority\"][i] == 0 and row[\"binary_annotation\"][i] == 1:\n",
    "            false_positives.append((row[\"Descriptions\"], row[\"rico_ranking\"][i], row[\"binary_reasonings\"][i]))\n",
    "print(len(false_positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e75f492-21eb-48bf-8f3d-b3739f04e4c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = random.sample(false_positives, 20)\n",
    "for fp in sample:\n",
    "    img = Image.open(\"../data/rico/unique_uis/combined/\" + str(fp[1]) + \".jpg\")\n",
    "    plt.imshow(img)\n",
    "    plt.grid(False)\n",
    "    plt.title(fp[1])\n",
    "    plt.show()\n",
    "    print(fp[0])\n",
    "    print(fp[2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
