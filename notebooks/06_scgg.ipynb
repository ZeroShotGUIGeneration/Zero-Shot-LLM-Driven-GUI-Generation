{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Text, Generator, Tuple, List, Optional, Dict, Set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import base64\n",
    "import ast\n",
    "import copy\n",
    "import imgkit\n",
    "import math\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from PIL import Image\n",
    "from tabulate import tabulate\n",
    "sns.set_theme()\n",
    "\n",
    "config = imgkit.config(wkhtmltoimage='C:/Program Files/wkhtmltopdf/bin/wkhtmltoimage.exe')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('display.max_colwidth', 5000)\n",
    "pd.options.display.float_format = '{:.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(prompt, model='gpt-4o', temp=0.50, n=1, max_tokens=30000, logprobs=False, top_logprobs=5, return_obj=True, verbose=False, num_rows=-1):\n",
    "    if verbose:\n",
    "        if num_rows == -1:\n",
    "            print('Generating completion...')\n",
    "        else:\n",
    "            print('[{}] - Generating completion...'.format(num_rows))\n",
    "    if logprobs:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "              model=model,\n",
    "              messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "              temperature=temp,\n",
    "              n=n,\n",
    "              logprobs=logprobs,\n",
    "        )\n",
    "    else:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "              model=model,\n",
    "              messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "              temperature=temp,\n",
    "              n=n,\n",
    "        )\n",
    "        if chat_completion.choices[0].finish_reason == 'length':\n",
    "            print(\"Response cut off. Starting a second request... Length: {}\".format(chat_completion.usage.completion_tokens))\n",
    "            prompt += '\\n -------- \\nYour last response was cut off. Continue exactly where you left.'\n",
    "            chat_completion_2 = client.chat.completions.create(\n",
    "              model=model,\n",
    "              messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                      {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": chat_completion.choices[0].message.content\n",
    "                    }\n",
    "                ],\n",
    "              temperature=temp,\n",
    "              n=n,\n",
    "        )\n",
    "            chat_completion.choices[0].message.content += chat_completion_2.choices[0].message.content\n",
    "            chat_completion.usage.completion_tokens += chat_completion_2.usage.completion_tokens\n",
    "            chat_completion.usage.prompt_tokens += chat_completion_2.usage.prompt_tokens\n",
    "            chat_completion.usage.total_tokens += chat_completion_2.usage.total_tokens\n",
    "    return chat_completion if return_obj else [choice.message.content for choice in chat_completion.choices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_html(completion):\n",
    "    html_content = re.search(r'<!DOCTYPE html>.*</html>', completion, re.DOTALL)\n",
    "    if html_content:\n",
    "        extracted_text = html_content.group()\n",
    "        extracted_text = extracted_text.replace('```html','').replace('```','')\n",
    "        return extracted_text\n",
    "    else:\n",
    "        html_content = re.search(r'<html>.*</html>', completion, re.DOTALL)\n",
    "        if html_content:\n",
    "            extracted_text = html_content.group()\n",
    "            extracted_text = extracted_text.replace('```html','').replace('```','')\n",
    "            return extracted_text\n",
    "    return ''\n",
    "\n",
    "def extract_html_cot(completion):\n",
    "    html_content = re.search(r'<!-- Start -->.*<!-- End -->', completion, re.DOTALL)\n",
    "    extracted_text = html_content.group()\n",
    "    extracted_text = extracted_text.replace('```html','').replace('```','')\n",
    "    return extracted_text\n",
    "\n",
    "def write_html_to_file_and_image(path, model_name, dataset):\n",
    "    for index, row in dataset.iterrows():\n",
    "        file_name = str(index)\n",
    "        with open(path+file_name+'.html', 'w', encoding='utf-8') as file:\n",
    "            print(path+file_name+'.html')\n",
    "            file.write(row[model_name])\n",
    "        try:\n",
    "            imgkit.from_string(row[model_name], path+file_name+'.jpg', config=config)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "def save_results(dataframe, method_name, keep_cols, completion_col, path_csv, path_html, html_extractor=extract_html, is_json=False):\n",
    "    df_copy = dataframe.copy()\n",
    "    selected_cols = ['RICO GUI', 'description', completion_col]\n",
    "    selected_cols.extend(keep_cols)\n",
    "    df_copy = df_copy[selected_cols]\n",
    "    df_copy['method'] = method_name\n",
    "    if is_json:\n",
    "        df_copy['generated_html'] =  df_copy[completion_col].apply(lambda x: html_extractor(x['choices'][0]['message']['content']))\n",
    "        df_copy['token_input'] = df_copy[completion_col].apply(lambda x: x['usage']['prompt_tokens'])\n",
    "        df_copy['token_output'] = df_copy[completion_col].apply(lambda x: x['usage']['completion_tokens'])\n",
    "    else:\n",
    "        df_copy['generated_html'] =  df_copy[completion_col].apply(lambda x: html_extractor(x.choices[0].message.content))\n",
    "        df_copy['token_input'] = df_copy[completion_col].apply(lambda x: x.usage.prompt_tokens)\n",
    "        df_copy['token_output'] = df_copy[completion_col].apply(lambda x: x.usage.completion_tokens)\n",
    "    for col in df_copy.columns:\n",
    "        if \"completion\" in col:\n",
    "            df_copy[col] = df_copy[col].to_dict()\n",
    "    df_copy.to_csv(path_csv + method_name + '.csv', index=False)\n",
    "    write_html_to_file_and_image(path_html, 'generated_html', df_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_descriptions_test = pd.read_csv('../data/generated/00_dataset_test/data/01_baselines/zs_instruction.csv')\n",
    "df_sample_descriptions_test['rico_ranking'] = df_sample_descriptions_test['rico_ranking'].apply(ast.literal_eval)\n",
    "df_sample_descriptions_test['binary_annotation'] = df_sample_descriptions_test['binary_annotation'].apply(ast.literal_eval)\n",
    "df_sample_descriptions_test.rename(columns={'Descriptions': 'description'}, inplace=True)\n",
    "df_sample_descriptions_test['filtered_rico_ids'] = df_sample_descriptions_test.apply(lambda x: [], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. k-Self-Critique Looping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_descriptions_with_prompts = df_sample_descriptions_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLACEHOLDER_PROTOTYPE = '{prototype}'\n",
    "PLACEHOLDER_FEEDBACK = '{feedback}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEEDBACK_PROMPT = \"\"\"Your task is to create feedback on a GUI prototype, that has been generated based on a high-level text description.\n",
    "\n",
    "### High-level text description:\n",
    "{summary}\n",
    "\n",
    "### GUI prototype in the form of HTML and CSS code:\n",
    "{prototype}\n",
    "\n",
    "### Your Task\n",
    "- Provide feedback on the prototype, regarding the following:\n",
    "    - What features would be also relevant to include into the prototype?\n",
    "    - How can the implementation of the current present features be improved?\n",
    "    - How can the design and layout of the overall prototype be improved?\n",
    "- Do not provide any specific implementations. Solely provide the feedback in text form.\n",
    "- Focus on HMTL and CSS implementation. \n",
    "- IMPORTANT: Avoid feedback, that requires any Java Script implementation.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFINEMENT_PROMPT = \"\"\"Improve a given GUI prototype based on feedback that is also provided.\n",
    "\n",
    "### High-level text description, the GUI prototype is based on:\n",
    "{summary}\n",
    "\n",
    "### Curent implementation of the GUI prototype in the form of HTML and CSS code:\n",
    "{prototype}\n",
    "\n",
    "### Feedback, that was created to improve the current prototype implementation:\n",
    "{feedback}\n",
    "\n",
    "### Your Task\n",
    "- Improve the Current GUI prototype, by integrating the provided Feedback into a new GUI prototype. \n",
    "- Respond with the revised HTML and CSS Code, without any additional explanation. \n",
    "- Provide the HTML and CSS together, do not seperate them.\n",
    "- IMPORTANT: Avoid adding any java script code to the prototype\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPERATURE = 0.5\n",
    "K = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,K):\n",
    "\n",
    "    # 1. Generate feedback and extract content\n",
    "    print('Generating feedback_v{}'.format(str(i)))\n",
    "    df_sample_descriptions_with_prompts['feedback_prompt_v'+str(i)] = df_sample_descriptions_with_prompts.apply(lambda row: FEEDBACK_PROMPT.replace(PLACEHOLDER_SUMMARY, row['description']).replace(PLACEHOLDER_PROTOTYPE, row['prototype_completion_content_v'+str(i)]), axis=1)\n",
    "    df_sample_descriptions_with_prompts['feedback_completion_v'+str(i)] = df_sample_descriptions_with_prompts.apply(lambda row: generate_completion(row['feedback_prompt_v'+str(i)], model='gpt-4o', temp=TEMPERATURE, logprobs=False, return_obj=True, verbose=True, num_rows=row.name), axis=1)\n",
    "    df_sample_descriptions_with_prompts['feedback_completion_content_v'+str(i)] = df_sample_descriptions_with_prompts.apply(lambda row: row['feedback_completion_v'+str(i)].choices[0].message.content, axis=1)\n",
    "    \n",
    "    # 2. Generate prototype and extract HTML\n",
    "    print('Implementing prototype_v{}'.format(str(i+1)))\n",
    "    df_sample_descriptions_with_prompts['prototype_prompt_v'+str(i+1)] = df_sample_descriptions_with_prompts.apply(lambda row: REFINEMENT_PROMPT.replace(PLACEHOLDER_SUMMARY, row['description']).replace(PLACEHOLDER_PROTOTYPE, row['prototype_completion_content_v'+str(i)]).replace(PLACEHOLDER_FEEDBACK, row['feedback_completion_content_v'+str(i)]), axis=1)\n",
    "    df_sample_descriptions_with_prompts['prototype_completion_v'+str(i+1)] = df_sample_descriptions_with_prompts.apply(lambda row: generate_completion(row['prototype_prompt_v'+str(i+1)], model='gpt-4o', temp=TEMPERATURE, logprobs=False, return_obj=True, verbose=True, num_rows=row.name), axis=1)\n",
    "    df_sample_descriptions_with_prompts['prototype_completion_content_v'+str(i+1)] = df_sample_descriptions_with_prompts.apply(lambda row: row['prototype_completion_v'+str(i+1)].choices[0].message.content, axis=1)\n",
    "    \n",
    "    # 3. Generate keep columns to save\n",
    "    feedback_keep_cols = ['feedback_completion_v'+str(j+1) for j in range(-1,i)]\n",
    "    prototype_keep_cols = ['prototype_completion_v'+str(x+1) for x in range(-1,i-1)]\n",
    "    keep_cols = feedback_keep_cols\n",
    "    keep_cols.extend(prototype_keep_cols)\n",
    "    try:\n",
    "        keep_cols.remove('prototype_completion_v0')\n",
    "    except:\n",
    "        pass\n",
    "    print(keep_cols)\n",
    "    \n",
    "    # 4. Save results\n",
    "    save_results(df_sample_descriptions_with_prompts, 'prototype_v'+str(i+1), keep_cols, 'prototype_completion_v'+str(i+1), '../data/generated/00_dataset_test/data/04_self_critique/base_zs_instruction/', '../data/generated/00_dataset_test/guis/04_self_critique/base_zs_instruction/prototype_v'+str(i+1)+'/', is_json=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
