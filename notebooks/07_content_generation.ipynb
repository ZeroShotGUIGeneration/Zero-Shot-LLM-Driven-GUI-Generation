{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06fab5ea-17c8-4503-9114-f7fb1474218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>div.output_scroll { height: 44em; }</style>\"))\n",
    "\n",
    "from typing import Text, Generator, Tuple, List, Optional, Dict, Set\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import uuid\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import math\n",
    "sns.set_theme()\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 5000)\n",
    "pd.set_option('display.max_colwidth', 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286e3d8c-4665-486f-9a7e-03dce6dbb695",
   "metadata": {},
   "source": [
    "# 1. OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "473c7850-b5a4-4efa-9c9b-e98ced7abb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39e677b6-41f9-4207-a571-b49433494d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(prompt, model='gpt-4o', temp=0.50, n=1, max_tokens=30000, logprobs=False, top_logprobs=5, return_obj=True, verbose=False, num_rows=-1):\n",
    "    if verbose:\n",
    "        if num_rows == -1:\n",
    "            print('Generating completion...')\n",
    "        else:\n",
    "            print('[{}] - Generating completion...'.format(num_rows))\n",
    "    if logprobs:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "              model=model,\n",
    "              messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "              temperature=temp,\n",
    "              n=n,\n",
    "              logprobs=logprobs,\n",
    "        )\n",
    "    else:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "              model=model,\n",
    "              messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                ],\n",
    "              temperature=temp,\n",
    "              n=n,\n",
    "        )\n",
    "        if chat_completion.choices[0].finish_reason == 'length':\n",
    "            print(\"Response cut off. Starting a second request... Length: {}\".format(chat_completion.usage.completion_tokens))\n",
    "            prompt += '\\n -------- \\nYour last response was cut off. Continue exactly where you left.'\n",
    "            chat_completion_2 = client.chat.completions.create(\n",
    "              model=model,\n",
    "              messages=[\n",
    "                    {\"role\": \"user\", \"content\": prompt},\n",
    "                      {\n",
    "                        \"role\": \"assistant\",\n",
    "                        \"content\": chat_completion.choices[0].message.content\n",
    "                    }\n",
    "                ],\n",
    "              temperature=temp,\n",
    "              n=n,\n",
    "              logprobs=logprobs,\n",
    "        )\n",
    "            chat_completion.choices[0].message.content += chat_completion_2.choices[0].message.content\n",
    "            chat_completion.usage.completion_tokens += chat_completion_2.usage.completion_tokens\n",
    "            chat_completion.usage.prompt_tokens += chat_completion_2.usage.prompt_tokens\n",
    "            chat_completion.usage.total_tokens += chat_completion_2.usage.total_tokens\n",
    "    return chat_completion if return_obj else [choice.message.content for choice in chat_completion.choices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b053942-78ab-49ac-98c1-83df5c6350a3",
   "metadata": {},
   "source": [
    "# 2. Load Dataset to Augment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34cb0158-65c0-4628-9abb-101beb39c87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_html_to_file_and_image(path, model_name, dataset):\n",
    "    for index, row in dataset.iterrows():\n",
    "        file_name = str(index) + '_' + str(row['name'])\n",
    "        with open(path+str(index)+'.html', 'w', encoding='utf-8') as file:\n",
    "            print(path+str(index)+'.html')\n",
    "            file.write(row[model_name])\n",
    "        try:\n",
    "            imgkit.from_string(row[model_name], path+file_name+'.jpg', config=config)\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "962a4a88-f3a6-49d2-8415-35a96a3ec23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html = pd.read_csv('../data/generated/00_dataset_test/data/01_baselines/zs_cot.csv')\n",
    "df_html = df_html[['description', 'generated_html']]\n",
    "df_html = df_html.rename(columns={'description':'name', 'generated_html':'html'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a503d6c2-9cbb-48d9-966d-ec54383da5e2",
   "metadata": {},
   "source": [
    "# 3. Text Content Generation Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f92d1da4-0ac6-4eef-b3eb-06fefd07ef3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLACEHOLDER_HTML = 'placeholder_html'\n",
    "PLACEHOLDER_DESCRIPTION = 'placeholder_description'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49645997-54cf-42fd-bafe-b359ad225ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEXT_CONTENT_GENERATION = '''\n",
    "You are given a GUI in HTML and CSS. This GUI is a first draft for the requirement \"placeholder_description\". To make it look more realistic, \n",
    "your task is to recreate the HTML and CSS, but add concrete example data where it is necessary. For example, instead of having \n",
    "simple placeholder text such as \"News 1\" and \"News headline 2\", provide real example data. This also includes to, for example, \n",
    "add more list items to a list. For images, provide good descriptions or names in the \"alt\" tag, we will use these descriptions to \n",
    "generate fitting images later. However, do not use names of real persons or real companies in this description. Also, make sure that\n",
    "the generated descriptions are not sensitive at all (avoiding all NSFW, violent and sexual content). If there is already sensitive content, change it to non-sensitive content.\n",
    "To each of these images, you MUST add an \"id\" tag, we need this for later mapping back the generated images. To display icons properly, include popular \n",
    "icon frameworks and use them. If icons are represented as inside <img> tags, replace them with proper icons from an icon framework. Do everything, that makes the data used in the GUI look real. Note that the generated images are quite large\n",
    "(1024 x 1024 px), therefore, if necessary, make sure to add proper sizing information to the CSS to avoid that the images are displayed\n",
    "overly large. However, do not change anything else in the HTML/CSS which would lead to changes in the design, layout, feature set etc. \n",
    "Do not provide any explanation, as the output, provide the same HTML/CSS but with replaced and/or extended example data.\n",
    "Again make sure to add an \"id\" tag to the images.\n",
    "\n",
    "HTML/CSS:\n",
    "\n",
    "placeholder_html\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a932b149-1fd8-4147-9669-dc7f0d7597f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html['html_added_content_prompt'] = df_html.apply(lambda row: PROMPT_TEXT_CONTENT_GENERATION.replace(PLACEHOLDER_DESCRIPTION, row['name']).replace(PLACEHOLDER_HTML, row['html']), axis=1)\n",
    "df_html['html_added_content_completion'] = df_html.apply(lambda row: generate_completion(row['html_added_content_prompt'], model='gpt-4o', temp=0.5, logprobs=False, return_obj=True, verbose=True, num_rows=row.name), axis=1)\n",
    "df_html['html_added_content_completion_content'] = df_html.apply(lambda row: row['html_added_content_completion'].choices[0].message.content, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dba9dbb-64a7-4d48-8e7a-551700b54a09",
   "metadata": {},
   "source": [
    "# 4. Image Extraction Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2cf422c-d999-4c37-b41d-4232feb41dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_IMAGE_EXTRACTION = '''\n",
    "You are given a GUI in HTML and CSS for the description \"placeholder_description\". Your task is to extract a list of all the images contained in the HTML. \n",
    "For each image, you should extract the HTML \"id\" tag, the \"alt\" text and provide a more detailed brief description\n",
    "of the image content. Do not extract images that represent icons, even though they might be represented with <img> tags. Do not provide any explanations, directly output  the list. Please provide the answer in the following format, provided as an example. In this example, the list contains\n",
    "one example object. Make sure to only use \" for the strings and inside strings use '. Example output format: [{\"id\": \"id1\", \"alt\": \"alt_text\", \"description\": \"image_description\"}]\n",
    "\n",
    "HTML/CSS:\n",
    "\n",
    "placeholder_html\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40f5da56-f3fb-4f41-b356-c9b51ada973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html['extract_images_prompt'] = df_html.apply(lambda row: PROMPT_IMAGE_EXTRACTION.replace(PLACEHOLDER_DESCRIPTION, row['name']).replace(PLACEHOLDER_HTML, row['html_added_content_completion_content']), axis=1)\n",
    "df_html['extract_images_completion'] = df_html.apply(lambda row: generate_completion(row['extract_images_prompt'], model='gpt-4o', temp=0.5, logprobs=False, return_obj=True, verbose=True, num_rows=row.name), axis=1)\n",
    "df_html['extract_images_completion_content'] = df_html.apply(lambda row: row['extract_images_completion'].choices[0].message.content, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c230b1d5-a0e0-4648-9e08-a05acaa7cf09",
   "metadata": {},
   "source": [
    "# 5. Generate Images and Upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f2afc97-1073-4761-b49f-7b5bc9c188c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PLACEHOLDER_IMAGES_LIST = 'placeholder_images_list'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d9d744e2-703c-41e8-b8d4-7c4f1cccf3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMTP_REWRITE_DESCRIPTION = '''You are given a short description for an image, that was used to generate an image. However,\n",
    "due to the description being somewhat sensitive (e.g., NSFW, violent or sexual direction), please rewrite the description to\n",
    "keep its general information but reduce the sensitivity. Do not provide any explanation, directly output the rewritten description.\n",
    "Description: placeholder_description\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04a709e2-850b-441c-b82b-ba30d58c4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "import boto3\n",
    "from PIL import Image\n",
    "import io\n",
    "import uuid\n",
    "\n",
    "S3_ClIENT = boto3.client('s3')\n",
    "BUCKET_NAME = 'bucket_name'\n",
    "BASE_IMAGE_URL = \"base_url\"\n",
    "PLACEHOLDER_URL = \"placeholder\"\n",
    "\n",
    "def get_placeholder_image_bytes():\n",
    "    with open('../data/images/placeholder.png', 'rb') as image_file:\n",
    "            image_data = image_file.read()\n",
    "            base64_encoded_data = base64.b64encode(image_data)\n",
    "            base64_string = base64_encoded_data.decode('utf-8')\n",
    "            image_bytes_placeholder = base64.b64decode(base64_string)\n",
    "            image_bytes_io_placeholder = io.BytesIO(image_bytes_placeholder)\n",
    "    return image_bytes_io_placeholder\n",
    "\n",
    "def generate_image(description, size=\"1024x1024\", quality=\"hd\", style=\"vivid\"):\n",
    "    try:\n",
    "        image_completion = client.images.generate(\n",
    "                  model='dall-e-3',\n",
    "                  prompt=description,\n",
    "                  size=\"1024x1024\",\n",
    "                  quality=quality,\n",
    "                  n=1,\n",
    "                  style=style,\n",
    "                  response_format='b64_json'\n",
    "            )\n",
    "        image_url = image_completion.data[0]\n",
    "        image_data = image_url.b64_json\n",
    "        image_bytes = base64.b64decode(image_data)\n",
    "        image_bytes_io = io.BytesIO(image_bytes)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print('Exception occurred for description: {}'.format(description))\n",
    "        try:\n",
    "            # Rewrite the description\n",
    "            rewrite_prompt = PROMTP_REWRITE_DESCRIPTION.replace(PLACEHOLDER_DESCRIPTION, description)\n",
    "            completion_rewrite = generate_completion(rewrite_prompt, model='gpt-4o', temp=0.50, n=1,\n",
    "                                                     max_tokens=15500, logprobs=False, return_obj=True)\n",
    "            print('Rewritten description: {}'.format(completion_rewrite.choices[0].message.content))\n",
    "            image_completion = client.images.generate(\n",
    "                      model='dall-e-3',\n",
    "                      prompt=completion_rewrite.choices[0].message.content,\n",
    "                      size=\"1024x1024\",\n",
    "                      quality=quality,\n",
    "                      n=1,\n",
    "                      style=style,\n",
    "                      response_format='b64_json'\n",
    "                )\n",
    "            image_url = image_completion.data[0]\n",
    "            image_data = image_url.b64_json\n",
    "            image_bytes = base64.b64decode(image_data)\n",
    "            image_bytes_io = io.BytesIO(image_bytes)\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            print('Exception occurred again for description: {}'.format(description))\n",
    "            image_bytes_io = get_placeholder_image_bytes()\n",
    "    return (image_bytes_io, image_completion)\n",
    "\n",
    "def upload_image_to_s3(image_bytes_io, bucket_name, object_name):\n",
    "    S3_ClIENT.upload_fileobj(\n",
    "    image_bytes_io, \n",
    "    bucket_name, \n",
    "    object_name,\n",
    "    ExtraArgs={'ContentType': 'image/png'}\n",
    "    )\n",
    "\n",
    "def generate_image_string(images_list):\n",
    "    output_str = ''\n",
    "    for image_obj in images_list:\n",
    "        output_str += \"<img> id: {} | new image src: {}\".format(image_obj['id'], image_obj['image_url']) + '\\n'\n",
    "    return output_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "596dd500-298e-487b-b4e2-1bc09f7695c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images_and_upload(images_list):\n",
    "    for image_obj in images_list:\n",
    "        generated_image, img_compl = generate_image(image_obj['description'])\n",
    "        image_id = str(uuid.uuid4())\n",
    "        upload_image_to_s3(generated_image, BUCKET_NAME, image_id + '.png')\n",
    "        image_url = BASE_IMAGE_URL.replace(PLACEHOLDER_URL, image_id)\n",
    "        print(image_url)\n",
    "        image_obj['image_id'] = image_id\n",
    "        image_obj['image_url'] = image_url\n",
    "        #image_obj['completion'] = img_compl.to_dict()\n",
    "    return images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bdb5d7-f607-4593-a00b-571ab09fc6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html['extract_images_completion'] = df_html.apply(lambda row: generate_images_and_upload(row['extract_images_completion_content']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "233d28a4-1546-4da0-8a13-0da66737fa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def replace_img_urls(images, html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    for image in images:\n",
    "        img_tag = soup.find('img', id=image['id'])\n",
    "        if img_tag:\n",
    "            img_tag['src'] = image['image_url']\n",
    "    modified_html = soup.prettify()\n",
    "    return modified_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8d445244-83f3-4dbf-a9d1-c4bcad99489a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html['html_images_replaced_completion'] = df_html.apply(lambda row: replace_img_urls(row['extract_images_completion_content'], row['html_added_content_completion_content']), axis=1)\n",
    "df_html['html_images_replaced_completion'] = df_html['html_images_replaced_completion'].apply(lambda x: x.replace('```html','').replace('```',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49b51e06-33f7-42cf-a7a6-735bbab21205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/0.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/1.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/2.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/3.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/4.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/5.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/6.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/7.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/8.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/9.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/10.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/11.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/12.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/13.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/14.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/15.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/16.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/17.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/18.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/19.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/20.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/21.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/22.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/23.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/24.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/25.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/26.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/27.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/28.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/29.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/30.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/31.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/32.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/33.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/34.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/35.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/36.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/37.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/38.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/39.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/40.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/41.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/42.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/43.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/44.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/45.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/46.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/47.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/48.html\n",
      "../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/49.html\n"
     ]
    }
   ],
   "source": [
    "write_html_to_file_and_image('../data/generated/00_dataset_test/guis/01_baselines/zs_cot_content/', 'html_images_replaced_completion', df_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "0bfe852d-3589-4c94-956a-e9906be5e5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html = df_html.rename(columns={'html_images_replaced_completion': 'generated_html'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a81235c-8638-4c3e-9573-fde218eaf928",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_html.to_csv('../data/generated/00_dataset_test/data/01_baselines/zs_cot_content.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
